{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vae.cvae import RnnVae\n",
    "from cupy.cuda import Device\n",
    "from sklearn.datasets.lfw import Bunch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from vae.corpus import ListDataset, OneHotCorpus\n",
    "from vae.metrics import diversity, validity, uniqueness\n",
    "from vae.misc import KLAnnealer, CosineAnnealingLRWithRestart, Logger, reject_outliers, LogPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 14 17:32:39 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 76%   82C    P2   266W / 250W |   4581MiB / 11172MiB |     67%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 76%   80C    P8    25W / 250W |     19MiB / 11172MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:42:00.0 Off |                  N/A |\n",
      "| 85%   90C    P2   102W / 250W |  10810MiB / 11172MiB |     71%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:43:00.0 Off |                  N/A |\n",
      "| 92%   90C    P2   171W / 250W |   9157MiB / 11170MiB |     77%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      2507      G   /usr/lib/xorg/Xorg                             7MiB |\n",
      "|    0    117983      C   python                                      3871MiB |\n",
      "|    0    128062      C   python3                                      691MiB |\n",
      "|    1      2507      G   /usr/lib/xorg/Xorg                             7MiB |\n",
      "|    2      2507      G   /usr/lib/xorg/Xorg                             7MiB |\n",
      "|    2    129232      C   python                                     10791MiB |\n",
      "|    3      2507      G   /usr/lib/xorg/Xorg                             7MiB |\n",
      "|    3     57992      C   ...bel/miniconda3/envs/text_gen/bin/python  2289MiB |\n",
      "|    3    126049      C   python                                      6849MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Bunch(\n",
    "    # Model\n",
    "    model=Bunch(\n",
    "        q=Bunch(\n",
    "            cell='gru',\n",
    "            d_h=64,\n",
    "            n_layers=1,\n",
    "            r_dropout=0.0,  # should be around 0 to help encoder train more easily\n",
    "            s_dropout=0.0  # same as `r_dropout`\n",
    "        ),\n",
    "        g=Bunch(\n",
    "            cell='gru',\n",
    "            n_layers=1,\n",
    "            r_dropout=0.3,\n",
    "            s_dropout=0.0\n",
    "        ),\n",
    "        d=Bunch(\n",
    "            n_filters=1\n",
    "        ),\n",
    "        d_z=64,\n",
    "        d_c=1,  # needed for `d` to work\n",
    "        p_word_dropout=0.0,\n",
    "        freeze_embeddings=True,\n",
    "        attention=True\n",
    "    ),\n",
    "    # Train\n",
    "    train=Bunch(\n",
    "        n_batch=64,\n",
    "        grad_clipping=5,\n",
    "        kl=Bunch(  # kl weight annealing params\n",
    "            i_start=0,\n",
    "            w_start=0.5,\n",
    "            w_max=0.5\n",
    "        ),\n",
    "        lr=Bunch(\n",
    "            value=1e-3,  # from `lr`\n",
    "            scheduler=Bunch(\n",
    "                n_period=3,\n",
    "                n_r=1,  # number of restarts in SGDR\n",
    "                n_mult=1,\n",
    "                lr_min=1e-3  # to `lr`\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    # Val\n",
    "    val=Bunch(\n",
    "        sample_params=Bunch(\n",
    "            n_beam=1,\n",
    "            coverage_penalty=False\n",
    "        )\n",
    "    ),\n",
    "    # Env\n",
    "    device_code=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    f'cuda:{args.device_code}' \n",
    "    if args.device_code >= 0 and torch.cuda.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "Device(device.index).use()  # cupy for SRU to work\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 1.02 s, total: 16.4 s\n",
      "Wall time: 16.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000000, 100000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/media/Molecules/molecules.csv'\n",
    "n_train, n_val = 1_000_000, 100_000\n",
    "\n",
    "%time data = pd.read_csv(data_path, usecols=['SMILES'], squeeze=True)\n",
    "data = data.sample(n_train + n_val)\n",
    "data = data.tolist()\n",
    "\n",
    "random.shuffle(data)\n",
    "train = data[:n_train]\n",
    "val = data[n_train: n_train + n_val]\n",
    "\n",
    "train = ListDataset(train)\n",
    "val = ListDataset(val)\n",
    "len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6203cc724c9346c9b66752d8e3e4c2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = OneHotCorpus(args.train.n_batch, device)\n",
    "train = corpus.fit_transform(train)\n",
    "# val = corpus.transform(val)\n",
    "ds_val = val  # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RnnVae(\n",
       "  (x_emb): Embedding(36, 36, padding_idx=19)\n",
       "  (encoder_rnn): GRU(36, 64)\n",
       "  (q_mu): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (q_logvar): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (decoder_rnn): GRU(101, 65)\n",
       "  (decoder_a): SelfAttention(\n",
       "    (linear_in): Linear(in_features=65, out_features=65, bias=False)\n",
       "    (linear_out): Linear(in_features=130, out_features=65, bias=False)\n",
       "    (activation): SELU()\n",
       "  )\n",
       "  (decoder_fc): Linear(in_features=65, out_features=36, bias=True)\n",
       "  (disc_cnn): CNNEncoder(\n",
       "    (_activation): ReLU()\n",
       "    (conv_layer_0): Conv1d(1, 1, kernel_size=(2,), stride=(1,))\n",
       "    (conv_layer_1): Conv1d(1, 1, kernel_size=(3,), stride=(1,))\n",
       "    (conv_layer_2): Conv1d(1, 1, kernel_size=(4,), stride=(1,))\n",
       "    (conv_layer_3): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (encoder): ModuleList(\n",
       "    (0): GRU(36, 64)\n",
       "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): GRU(101, 65)\n",
       "    (1): SelfAttention(\n",
       "      (linear_in): Linear(in_features=65, out_features=65, bias=False)\n",
       "      (linear_out): Linear(in_features=130, out_features=65, bias=False)\n",
       "      (activation): SELU()\n",
       "    )\n",
       "    (2): Linear(in_features=65, out_features=36, bias=True)\n",
       "  )\n",
       "  (vae): ModuleList(\n",
       "    (0): Embedding(36, 36, padding_idx=19)\n",
       "    (1): ModuleList(\n",
       "      (0): GRU(36, 64)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): GRU(101, 65)\n",
       "      (1): SelfAttention(\n",
       "        (linear_in): Linear(in_features=65, out_features=65, bias=False)\n",
       "        (linear_out): Linear(in_features=130, out_features=65, bias=False)\n",
       "        (activation): SELU()\n",
       "      )\n",
       "      (2): Linear(in_features=65, out_features=36, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (discriminator): ModuleList(\n",
       "    (0): CNNEncoder(\n",
       "      (_activation): ReLU()\n",
       "      (conv_layer_0): Conv1d(1, 1, kernel_size=(2,), stride=(1,))\n",
       "      (conv_layer_1): Conv1d(1, 1, kernel_size=(3,), stride=(1,))\n",
       "      (conv_layer_2): Conv1d(1, 1, kernel_size=(4,), stride=(1,))\n",
       "      (conv_layer_3): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RnnVae(\n",
    "    **args.model,\n",
    "    n_len=corpus.n_len,\n",
    "    x_vocab=corpus.vocab\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p)c+Cn)S(27'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.reverse(model.sample_sentence(1, **args.val.sample_params)[2])[0]  # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epoch = sum(args.train.lr.scheduler.n_period * (args.train.lr.scheduler.n_mult ** i)\n",
    "              for i in range(args.train.lr.scheduler.n_r))\n",
    "kl_annealer = KLAnnealer(**args.train.kl, n_epoch=n_epoch)\n",
    "xs = np.linspace(0, n_epoch, num=n_epoch + 1)\n",
    "ts = np.array([kl_annealer(i) for i in xs])\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('kl weight')\n",
    "plt.plot(xs, ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_params = lambda: (p for p in model.vae.parameters() if p.requires_grad)\n",
    "trainer = optim.Adam(get_params(), lr=args.train.lr.value)\n",
    "lr_scheduler = CosineAnnealingLRWithRestart(trainer, **args.train.lr.scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415e282df95c4a0c9928bb97af51ff97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train()\n",
    "T = tqdm.tqdm_notebook(range(n_epoch))\n",
    "n_iter, n_last = len(train), 100\n",
    "elog, ilog = Logger(), Logger()\n",
    "\n",
    "for epoch in T:\n",
    "    # Epoch start\n",
    "    kl_weight = kl_annealer(epoch)\n",
    "    \n",
    "    # Iters\n",
    "    for i, x in enumerate(train):\n",
    "        # Forward\n",
    "        kl_loss, recon_loss = model(x, use_c_prior=True)\n",
    "        loss = kl_weight * kl_loss + recon_loss\n",
    "        \n",
    "        # Backward\n",
    "        trainer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(get_params(), args.train.grad_clipping)\n",
    "        trainer.step()\n",
    "        \n",
    "        # Log\n",
    "        lr = trainer.param_groups[0]['lr']\n",
    "        ilog.append({\n",
    "            'epoch': epoch,\n",
    "            'kl_loss': kl_loss.item(),\n",
    "            'recon_loss': recon_loss.item(),\n",
    "            'loss': loss.item(),\n",
    "            'kl_weight': kl_weight,\n",
    "            'lr': lr\n",
    "        })\n",
    "        \n",
    "        # Update T\n",
    "        kl_loss_value = np.mean(ilog['kl_loss'][-n_last:])\n",
    "        recon_loss_value = np.mean(ilog['recon_loss'][-n_last:])\n",
    "        loss_value = np.mean(ilog['loss'][-n_last:])\n",
    "        postfix_strs = []\n",
    "        postfix_strs.append(f'i={i}/{n_iter}')\n",
    "        postfix_strs.append(f'kl_loss={kl_loss_value:.5f}')\n",
    "        postfix_strs.append(f'recon_loss={recon_loss_value:.5f}')\n",
    "        postfix_strs.append(f'loss={loss_value:.5f}')\n",
    "        postfix_strs.append(f'klw={kl_weight:.3f} lr={lr:.5f}')\n",
    "        T.set_postfix_str(' '.join(postfix_strs))\n",
    "        T.refresh()\n",
    "    \n",
    "    # Log\n",
    "    sent = corpus.reverse(model.sample_sentence(1, **args.val.sample_params)[2])[0]\n",
    "    elog.append({\n",
    "        **{k: v for k, v in ilog[-1].items() if 'loss' not in k},\n",
    "        'kl_loss': kl_loss_value,\n",
    "        'recon_loss': recon_loss_value,\n",
    "        'loss': loss_value,\n",
    "        'sent': sent\n",
    "    })\n",
    "    \n",
    "    # Print result\n",
    "    print(f\"[epoch={epoch}]: '{sent}'\")\n",
    "    \n",
    "    # Epoch end\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = LogPlotter(elog)\n",
    "plotter.grid([\n",
    "    'kl_loss', 'recon_loss',\n",
    "    'loss', 'lr'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as Oktai\n",
    "def test_model(dataset, n_gen=1000, n_other=1000):\n",
    "    gen_smiles = corpus.reverse(model.sample_sentence(n_gen, **args.val.sample_params)[2])\n",
    "    other_smiles = random.sample(list(dataset), n_other)\n",
    "\n",
    "    internal_diversity_val = diversity(gen_smiles)\n",
    "    external_diversity_val = diversity(gen_smiles, other_smiles)  # TODO: check it\n",
    "    validity_val = validity(gen_smiles)\n",
    "    uniqueness_val = uniqueness(gen_smiles)\n",
    "\n",
    "    print('\\n###########################')\n",
    "    print('Internal Diversity = {}'.format(internal_diversity_val))\n",
    "    print('External Diversity = {}'.format(external_diversity_val))\n",
    "    print('Validity = {}'.format(validity_val))\n",
    "    print('Uniqueness = {}'.format(uniqueness_val))\n",
    "    print('############################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Bunch(save='vae.pt')\n",
    "torch.save((args, model), path.save)\n",
    "!du -sh {path.save}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
